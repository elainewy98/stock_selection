{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jqdata import *\n",
    "from jqlib.technical_analysis import *\n",
    "from jqfactor import get_factor_values\n",
    "from jqfactor import winsorize\n",
    "from jqfactor import standardlize\n",
    "from jqfactor import neutralize\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from six import StringIO\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Trading Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In order to acquire factor data at the end of each month, we need to get a list of the ending date of each month.\n",
    "\n",
    "- input parameters\n",
    "    - period: period_type {'W':week,'M':month,'Q':Quarter'}\n",
    "    - start_date\n",
    "    - end_date\n",
    "\n",
    "- output: return ending date of each month between start_date and end_date\n",
    "\n",
    "We choose 2010-01-01 as start_date and 2018-01-01 as end_date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the datelist of specific period 'W、M、Q'\n",
    "def get_period_date(period,start_date, end_date):\n",
    "    \n",
    "    #stock code here is not important because we just want to identify the trading day\n",
    "    stock_data = get_price('000001.XSHE',start_date,end_date,'daily',fields=['close'],panel=False)\n",
    "    \n",
    "    #record the trading days of each period \n",
    "    stock_data['date']=stock_data.index\n",
    "\n",
    "    #resample data to the period bin and take the last data as the value of the bin\n",
    "    #price/volume \n",
    "    period_stock_data = stock_data.resample(period).last()\n",
    "    date = period_stock_data.index\n",
    "    pydate_array = date.to_pydatetime()\n",
    "    \n",
    "    date_only_array = np.vectorize(lambda s: s.strftime('%Y-%m-%d'))(pydate_array)\n",
    "    date_only_series = pd.Series(date_only_array)\n",
    "    \n",
    "    start_date = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    start_date =start_date-datetime.timedelta(days=1)\n",
    "    start_date = start_date.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    date_list = date_only_series.values.tolist()\n",
    "    date_list.insert(0,start_date)\n",
    "    \n",
    "    return date_list\n",
    "\n",
    "#eg\n",
    "#np.array(get_period_date('M','2010-01-01', '2018-01-01'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get Stocks Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Available stock pool: zjw I64 I65\n",
    "- Filter stocks \n",
    "    - rule out ST stocks\n",
    "    - rule out stocks listed less than 3 months from current date(including new, delisted and suspended stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_stop(stocks,current_date,n=30*3):\n",
    "    \n",
    "    stockList=[]\n",
    "    current_date = datetime.datetime.strptime(current_date, \"%Y-%m-%d\")\n",
    "    \n",
    "    for stock in stocks:\n",
    "        start_date = get_security_info(stock).start_date\n",
    "        if start_date < (current_date - datetime.timedelta(days=n)).date():\n",
    "            stockList.append(stock)\n",
    "    return stockList\n",
    "\n",
    "\n",
    "def get_stock(cur_date):\n",
    "    \n",
    "    #get stock pool\n",
    "    stockList = get_industry_stocks('I64')+get_industry_stocks('I65')\n",
    "        \n",
    "    #rule out ST\n",
    "    st_data = get_extras('is_st',stockList, count = 1,end_date=cur_date)\n",
    "    stockList = [stock for stock in stockList if not st_data[stock][0]]\n",
    "    \n",
    "    #rule out stocks listed less than 3 months from the begin_date\n",
    "    #rule out delisted/suspended\n",
    "    stockList = detect_stop(stockList,cur_date)\n",
    "    \n",
    "    return stockList\n",
    "#eg\n",
    "#get_stock('000300.XSHG','2017-06-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Selection and Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature Selection\n",
    "    - On the last trading day of each month, calculate the factors exposures as the original features.These factors have been proved effecitve in the literature we find.\n",
    "\n",
    "- Feature Preprocessing\n",
    "    1. winsorize:\n",
    "        - limiting extreme values in the data to reduce the effect of possibly spurious outliers. \n",
    "        - Realized by $\\textit{winsorize()}$ provided by JoinQuant API.\n",
    "    \n",
    "    2. fill Nan: \n",
    "        - Replace Nans with the mean of the industry the stock belongs to. \n",
    "        - Realized by $\\textit{replace_nan_indu()}$\n",
    "    \n",
    "    3. neutralize the market cap of the industry:\n",
    "        - When we are using factors in the pool to evaluate stocks, there will be problems that these factors will be affected by some factors outside the pool, which will generate results under expectation.\n",
    "        - For instance,P/B is highly related with market cap, so if we're using the P/B ratio before market cap neutralization, the stocks we choose will be mostly those with those with specific market cap feature.\n",
    "        - Secondly, P/B ratio of those \"sunrise\" and \"sunset\" industry are generally similar respectively, meaning that industry also has impact on the the financial indicators, and we would very likely to get some results with unnecessary preferrences.\n",
    "        - To address the 2 problems above, we are using neutralizing by industry and market cap: Perform a linear regression the factors value on the industry dummy variable and log of market cap, take the residuals as the new factor exposures.\n",
    "        - Realized by $\\textit{neutralize()}$ provided by JoinQuant API.\n",
    "    \n",
    "    4. standardlization:\n",
    "        - Measures of factors values are diversed, so we need to standardlized them.\n",
    "        - Realized by $\\textit{standardlize()}$ provided by JoinQuant API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given stock, get corresponding industry\n",
    "#industries are categorized by \"zjw\"\n",
    "def get_industry_name(stocks_dict, value):\n",
    "    return [k for k, v in stocks_dict.items() if value in v]\n",
    "\n",
    "#deal with missing values\n",
    "def replace_nan_indu(factor_data,stockList,industry_code,date):\n",
    "    #first replace Nan with the mean of the industry the stock belongs to \n",
    "    #there will still be Nans, then replace them with the mean of all stocks\n",
    "    \n",
    "    stocks_dict = {}\n",
    "    data_temp = pd.DataFrame(index=industry_code,columns=factor_data.columns)\n",
    "    \n",
    "    for i in industry_code:\n",
    "        temp = get_industry_stocks(i, date)\n",
    "        stocks_dict[i] = list(set(temp).intersection(set(stockList)))\n",
    "        data_temp.loc[i]=mean(factor_data.loc[stocks_dict[i],:])\n",
    "        \n",
    "    #first replace Nan with the mean of the industry the stock belongs to\n",
    "    for factor in data_temp.columns:\n",
    "        null_industry = list(data_temp.loc[pd.isnull(data_temp[factor]),factor].keys())\n",
    "        for i in null_industry:\n",
    "            data_temp.loc[i,factor] = mean(data_temp[factor])\n",
    "            \n",
    "        #there will still be Nans, then replace them with the mean of all stocks\n",
    "        null_stock=list(factor_data.loc[pd.isnull(factor_data[factor]),factor].keys())\n",
    "        for i in null_stock:\n",
    "            industry=get_industry_name(stocks_dict, i)\n",
    "            if industry:\n",
    "                factor_data.loc[i,factor]=data_temp.loc[industry[0],factor] \n",
    "            else:\n",
    "                factor_data.loc[i,factor]=mean(factor_data[factor])\n",
    "    return factor_data\n",
    "\n",
    "#data preprocessing\n",
    "def data_preprocessing(factor_data,stockList,industry_code,date):\n",
    "    \n",
    "    #winsorize data to eliminate of the effect of outliers\n",
    "    factor_data = winsorize(factor_data, qrange=[0.05,0.95],inf2nan=False, axis=0)\n",
    "    \n",
    "    #deal with missing values\n",
    "    factor_data = replace_nan_indu(factor_data,stockList,industry_code,date)\n",
    "    \n",
    "    #neutralize the data to avoid the effect that industry put on related factor\n",
    "    factor_data = neutralize(factor_data, how=['zjw', 'market_cap'], date=date, axis=0)\n",
    "    \n",
    "    #standardize the data\n",
    "    factor_data = standardlize(factor_data,axis=0)\n",
    "    \n",
    "    return factor_data\n",
    "\n",
    "#acquire the factors data for all stocks on time 'date'\n",
    "def get_factor_data(stock,date):\n",
    "    \n",
    "    data=pd.DataFrame(index=stock)\n",
    "    q = query(valuation,balance,cash_flow,income,indicator).filter(valuation.code.in_(stock))\n",
    "    df = get_fundamentals(q, date)\n",
    "    \n",
    "    df['market_cap']=df['market_cap']*100000000\n",
    "    \n",
    "    factor_data=get_factor_values(stock,['roe_ttm','roa_ttm','total_asset_turnover_rate',\\\n",
    "                               'net_operate_cash_flow_ttm','net_profit_ttm',\\\n",
    "                              'cash_to_current_liability','current_ratio',\\\n",
    "                             'gross_income_ratio','non_recurring_gain_loss',\\\n",
    "                            'operating_revenue_ttm','net_profit_growth_rate',\\\n",
    "                            'sharpe_ratio_20','sharpe_ratio_60','sharpe_ratio_120',\\\n",
    "                            'net_debt','EBIT','intangible_asset_ratio','DEGM',\\\n",
    "                            'roic_ttm','total_asset_growth_rate',\\\n",
    "                            'operating_revenue_growth_rate','net_operate_cashflow_growth_rate'],\\\n",
    "                            end_date=date,count=1)\n",
    "    \n",
    "    factor=pd.DataFrame(index=stock)\n",
    "    for i in factor_data.keys():\n",
    "        factor[i]=factor_data[i].iloc[0,:]\n",
    "    df.index = df['code']\n",
    "    del df['code'],df['id']\n",
    "    \n",
    "    #combine\n",
    "    df=pd.concat([df,factor],axis=1)\n",
    "    \n",
    "    # Profitability indicator\n",
    "    df['net_assets']=df['total_assets']-df['total_liability']\n",
    "    \n",
    "    data['roic_ttm']=df['roic_ttm']\n",
    "    data['log_market_cap']=np.log(df['market_cap'])\n",
    "    data['pe_ratio']=df['net_profit_ttm']/df['market_cap']\n",
    "    data['pb_ratio']=1/df['pb_ratio']\n",
    "    data['ps_ratio']=1/df['ps_ratio']\n",
    "    data['roe_ttm']=df['roe_ttm']\n",
    "    data['roe_q']=df['roe']\n",
    "    data['roa_ttm']=df['roa_ttm']\n",
    "    data['roa_q']=df['roa']\n",
    "    data['gross_profit_margin_ttm']=df['gross_income_ratio']\n",
    "    data['gross_profit_margin_q']=df['gross_profit_margin']\n",
    "    data['profit_margin_q']=df['adjusted_profit']/df['operating_revenue']\n",
    "\n",
    "    #financial indicator - leverage\n",
    "    data['financial_leverage']=df['total_assets']/df['net_assets']\n",
    "    data['debt_to_equity_ratio']=df['total_non_current_liability']/df['net_assets']\n",
    "    data['cash_ratio']=df['cash_to_current_liability']\n",
    "    data['current_ratio']=df['current_ratio']\n",
    "    \n",
    "    #growth indicators\n",
    "    data['intangible_asset_ratio']=df['intangible_asset_ratio']\n",
    "    data['total_asset_growth_rate']=df['total_asset_growth_rate']\n",
    "    data['profit_margin_growth_rate']=df['DEGM']\n",
    "    data['net_profit_growth_rate']=df['net_profit_growth_rate']\n",
    "    data['asset_turnover_ttm']=df['total_asset_turnover_rate']\n",
    "    data['asset_turnover_q']=df['operating_revenue']/df['total_assets']\n",
    "    data['operating_revenue_growth_rate']=df['operating_revenue_growth_rate']\n",
    "    data['net_operate_cf_growth_rate']=df['net_operate_cashflow_growth_rate']\n",
    "    \n",
    "    #momentum indicators\n",
    "    ##contrarian\n",
    "    stock_close=get_price(stock, count = 60*20+1, end_date=date, frequency='daily', fields=['close'],panel=False)['close']\n",
    "    data['contrarian_1m']=stock_close.iloc[-1]/stock_close.iloc[-20]-1\n",
    "    data['contrarian_3m']=stock_close.iloc[-1]/stock_close.iloc[-60]-1\n",
    "    data['contrarian_6m']=stock_close.iloc[-1]/stock_close.iloc[-120]-1\n",
    "    data['contrarian_12m']=stock_close.iloc[-1]/stock_close.iloc[-240]-1\n",
    "\n",
    "    ##get turnover\n",
    "    data_turnover_ratio=pd.DataFrame()\n",
    "    data_turnover_ratio['code']=stock\n",
    "    trade_days=list(get_trade_days(end_date=date, count=240*2))\n",
    "    for i in trade_days:\n",
    "        q = query(valuation.code,valuation.turnover_ratio).filter(valuation.code.in_(stock))\n",
    "        temp = get_fundamentals(q, i)\n",
    "        data_turnover_ratio=pd.merge(data_turnover_ratio, temp,how='left',on='code')\n",
    "        data_turnover_ratio=data_turnover_ratio.rename(columns={'turnover_ratio':i})\n",
    "    data_turnover_ratio=data_turnover_ratio.set_index('code').T  \n",
    "    \n",
    "    ##daily average turnover ratio in the closet N months\n",
    "    data['stock_turnover_1m']=mean(data_turnover_ratio.iloc[-20:])\n",
    "    data['stock_turnover_3m']=mean(data_turnover_ratio.iloc[-60:])\n",
    "    data['stock_turnover_6m']=mean(data_turnover_ratio.iloc[-120:])\n",
    "    data['stock_turnover_12m']=mean(data_turnover_ratio.iloc[-240:])\n",
    "    \n",
    "    data['bias_stock_turnover_1m']=mean(data_turnover_ratio.iloc[-20:])/mean(data_turnover_ratio)-1\n",
    "    data['bias_stock_turnover_3m']=mean(data_turnover_ratio.iloc[-60:])/mean(data_turnover_ratio)-1\n",
    "    data['bias_stock_turnover_6m']=mean(data_turnover_ratio.iloc[-120:])/mean(data_turnover_ratio)-1\n",
    "    data['bias_stock_turnover_12m']=mean(data_turnover_ratio.iloc[-240:])/mean(data_turnover_ratio)-1\n",
    "\n",
    "    #risk indicators\n",
    "    ##volatility \n",
    "    stock_pchg=stock_close.pct_change().iloc[1:]\n",
    "    data['volatility_of_return_1m']=stock_pchg.iloc[-20:].std()\n",
    "    data['volatility_of_return_3m']=stock_pchg.iloc[-60:].std()\n",
    "    data['volatility_of_return_6m']=stock_pchg.iloc[-120:].std()\n",
    "    data['volatility_of_return_12m']=stock_pchg.iloc[-240:].std()\n",
    "    \n",
    "    ##sharpe ratio\n",
    "    data['sharpe_ratio_20d']=df['sharpe_ratio_20']\n",
    "    data['sharpe_ratio_60d']=df['sharpe_ratio_60']\n",
    "    data['sharpe_ratio_120d']=df['sharpe_ratio_120']\n",
    "      \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Pickle File (DONOT RUN THIS SECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peroid = 'M' #month\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2018-01-01'\n",
    "\n",
    "#industry code \n",
    "industry_code = ['I64','I65']\n",
    "\n",
    "#get trading dates \n",
    "dateList = get_period_date(peroid,start_date, end_date)\n",
    "\n",
    "factor_init_data = {}\n",
    "factor_final_data = {}\n",
    "\n",
    "\n",
    "for date in dateList:\n",
    "    \n",
    "    print(date)\n",
    "        \n",
    "    stockList=get_stock(date)\n",
    "\n",
    "    factor_init_data[date] = get_factor_data(stockList,date)\n",
    "    factor_final_data[date] = data_preprocessing(factor_init_data[date],stockList,industry_code,date)\n",
    "    \n",
    "content = pickle.dumps(factor_final_data) \n",
    "write_file('factor_data.pkl', content, append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_read=open('factor_data.pkl','rb')\n",
    "factors=pickle.load(factor_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Type: dict\n",
    "- key: date (the date of the last trading day of each month)\n",
    "- value: the corresponding factors data of each period\n",
    "    - value data format: dataframe\n",
    "    - index: stock codes \n",
    "    - columns: factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roic_ttm</th>\n",
       "      <th>log_market_cap</th>\n",
       "      <th>pe_ratio</th>\n",
       "      <th>pb_ratio</th>\n",
       "      <th>ps_ratio</th>\n",
       "      <th>roe_ttm</th>\n",
       "      <th>roe_q</th>\n",
       "      <th>roa_ttm</th>\n",
       "      <th>roa_q</th>\n",
       "      <th>gross_profit_margin_ttm</th>\n",
       "      <th>gross_profit_margin_q</th>\n",
       "      <th>profit_margin_q</th>\n",
       "      <th>financial_leverage</th>\n",
       "      <th>debt_to_equity_ratio</th>\n",
       "      <th>cash_ratio</th>\n",
       "      <th>current_ratio</th>\n",
       "      <th>intangible_asset_ratio</th>\n",
       "      <th>total_asset_growth_rate</th>\n",
       "      <th>profit_margin_growth_rate</th>\n",
       "      <th>net_profit_growth_rate</th>\n",
       "      <th>asset_turnover_ttm</th>\n",
       "      <th>asset_turnover_q</th>\n",
       "      <th>operating_revenue_growth_rate</th>\n",
       "      <th>net_operate_cf_growth_rate</th>\n",
       "      <th>contrarian_1m</th>\n",
       "      <th>contrarian_3m</th>\n",
       "      <th>contrarian_6m</th>\n",
       "      <th>contrarian_12m</th>\n",
       "      <th>stock_turnover_1m</th>\n",
       "      <th>stock_turnover_3m</th>\n",
       "      <th>stock_turnover_6m</th>\n",
       "      <th>stock_turnover_12m</th>\n",
       "      <th>bias_stock_turnover_1m</th>\n",
       "      <th>bias_stock_turnover_3m</th>\n",
       "      <th>bias_stock_turnover_6m</th>\n",
       "      <th>bias_stock_turnover_12m</th>\n",
       "      <th>volatility_of_return_1m</th>\n",
       "      <th>volatility_of_return_3m</th>\n",
       "      <th>volatility_of_return_6m</th>\n",
       "      <th>volatility_of_return_12m</th>\n",
       "      <th>sharpe_ratio_20d</th>\n",
       "      <th>sharpe_ratio_60d</th>\n",
       "      <th>sharpe_ratio_120d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000503.XSHE</th>\n",
       "      <td>-0.512500</td>\n",
       "      <td>-1.120879</td>\n",
       "      <td>-0.388257</td>\n",
       "      <td>-1.077097</td>\n",
       "      <td>-1.709625</td>\n",
       "      <td>-0.692879</td>\n",
       "      <td>-1.075033</td>\n",
       "      <td>-0.733108</td>\n",
       "      <td>-1.302710</td>\n",
       "      <td>-0.375977</td>\n",
       "      <td>-0.528139</td>\n",
       "      <td>-1.156109</td>\n",
       "      <td>-1.214253</td>\n",
       "      <td>-1.976323</td>\n",
       "      <td>0.588487</td>\n",
       "      <td>-0.425839</td>\n",
       "      <td>-1.113684</td>\n",
       "      <td>0.850188</td>\n",
       "      <td>-1.040031</td>\n",
       "      <td>-1.695110</td>\n",
       "      <td>-0.893657</td>\n",
       "      <td>-1.091178</td>\n",
       "      <td>0.771176</td>\n",
       "      <td>-0.717801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.129151</td>\n",
       "      <td>-1.129151</td>\n",
       "      <td>-1.129151</td>\n",
       "      <td>0.380998</td>\n",
       "      <td>0.674747</td>\n",
       "      <td>0.238648</td>\n",
       "      <td>-0.055786</td>\n",
       "      <td>0.689594</td>\n",
       "      <td>1.206733</td>\n",
       "      <td>0.553964</td>\n",
       "      <td>-0.238196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.129151</td>\n",
       "      <td>-1.129151</td>\n",
       "      <td>-1.129151</td>\n",
       "      <td>0.458526</td>\n",
       "      <td>-0.150085</td>\n",
       "      <td>0.499285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000606.XSHE</th>\n",
       "      <td>-0.055995</td>\n",
       "      <td>-0.195735</td>\n",
       "      <td>-0.053428</td>\n",
       "      <td>-0.116181</td>\n",
       "      <td>-0.005641</td>\n",
       "      <td>-0.062522</td>\n",
       "      <td>-0.068488</td>\n",
       "      <td>-0.064927</td>\n",
       "      <td>-0.075975</td>\n",
       "      <td>-0.107351</td>\n",
       "      <td>-0.109912</td>\n",
       "      <td>-0.087277</td>\n",
       "      <td>-0.085980</td>\n",
       "      <td>-0.041941</td>\n",
       "      <td>-0.038178</td>\n",
       "      <td>-0.104063</td>\n",
       "      <td>-0.059347</td>\n",
       "      <td>-0.029840</td>\n",
       "      <td>0.006779</td>\n",
       "      <td>-0.027945</td>\n",
       "      <td>-0.034239</td>\n",
       "      <td>-0.043841</td>\n",
       "      <td>-0.017284</td>\n",
       "      <td>0.008792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.196095</td>\n",
       "      <td>-0.196095</td>\n",
       "      <td>-0.196095</td>\n",
       "      <td>-0.111905</td>\n",
       "      <td>-0.124008</td>\n",
       "      <td>-0.124254</td>\n",
       "      <td>-0.127046</td>\n",
       "      <td>-0.016064</td>\n",
       "      <td>-0.016436</td>\n",
       "      <td>-0.044982</td>\n",
       "      <td>-0.064437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.196095</td>\n",
       "      <td>-0.196095</td>\n",
       "      <td>-0.196095</td>\n",
       "      <td>0.005883</td>\n",
       "      <td>-0.036394</td>\n",
       "      <td>-0.054728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000676.XSHE</th>\n",
       "      <td>-1.274996</td>\n",
       "      <td>-2.107013</td>\n",
       "      <td>-1.572833</td>\n",
       "      <td>-1.491951</td>\n",
       "      <td>0.184579</td>\n",
       "      <td>-1.423820</td>\n",
       "      <td>-1.946296</td>\n",
       "      <td>-0.878980</td>\n",
       "      <td>-1.575495</td>\n",
       "      <td>-1.118237</td>\n",
       "      <td>-1.461499</td>\n",
       "      <td>-1.662347</td>\n",
       "      <td>-0.519623</td>\n",
       "      <td>-1.809495</td>\n",
       "      <td>-0.668470</td>\n",
       "      <td>-0.522201</td>\n",
       "      <td>-0.662788</td>\n",
       "      <td>-0.965518</td>\n",
       "      <td>-0.695595</td>\n",
       "      <td>-0.679368</td>\n",
       "      <td>-0.633371</td>\n",
       "      <td>-0.449688</td>\n",
       "      <td>-0.449884</td>\n",
       "      <td>-0.276353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.144547</td>\n",
       "      <td>-2.144547</td>\n",
       "      <td>-2.144547</td>\n",
       "      <td>-2.332846</td>\n",
       "      <td>-1.680949</td>\n",
       "      <td>-1.757855</td>\n",
       "      <td>-1.574726</td>\n",
       "      <td>-0.830873</td>\n",
       "      <td>-0.036228</td>\n",
       "      <td>-0.499266</td>\n",
       "      <td>0.035731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.144547</td>\n",
       "      <td>-2.144547</td>\n",
       "      <td>-2.144547</td>\n",
       "      <td>0.076652</td>\n",
       "      <td>-1.010742</td>\n",
       "      <td>-0.564930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000835.XSHE</th>\n",
       "      <td>-0.055995</td>\n",
       "      <td>-0.195735</td>\n",
       "      <td>-0.053428</td>\n",
       "      <td>-0.116181</td>\n",
       "      <td>-0.005641</td>\n",
       "      <td>-0.062522</td>\n",
       "      <td>-0.068488</td>\n",
       "      <td>-0.064927</td>\n",
       "      <td>-0.075975</td>\n",
       "      <td>-0.107351</td>\n",
       "      <td>-0.109912</td>\n",
       "      <td>-0.087277</td>\n",
       "      <td>-0.085980</td>\n",
       "      <td>-0.041941</td>\n",
       "      <td>-0.038178</td>\n",
       "      <td>-0.104063</td>\n",
       "      <td>-0.059347</td>\n",
       "      <td>-0.029840</td>\n",
       "      <td>0.006779</td>\n",
       "      <td>-0.027945</td>\n",
       "      <td>-0.034239</td>\n",
       "      <td>-0.043841</td>\n",
       "      <td>-0.017284</td>\n",
       "      <td>0.008792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.196095</td>\n",
       "      <td>-0.196095</td>\n",
       "      <td>-0.196095</td>\n",
       "      <td>-0.111905</td>\n",
       "      <td>-0.124008</td>\n",
       "      <td>-0.124254</td>\n",
       "      <td>-0.127046</td>\n",
       "      <td>-0.016064</td>\n",
       "      <td>-0.016436</td>\n",
       "      <td>-0.044982</td>\n",
       "      <td>-0.064437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.196095</td>\n",
       "      <td>-0.196095</td>\n",
       "      <td>-0.196095</td>\n",
       "      <td>0.005883</td>\n",
       "      <td>-0.036394</td>\n",
       "      <td>-0.054728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002072.XSHE</th>\n",
       "      <td>-0.991742</td>\n",
       "      <td>-0.047729</td>\n",
       "      <td>-2.519291</td>\n",
       "      <td>-1.350659</td>\n",
       "      <td>-0.212915</td>\n",
       "      <td>-1.649759</td>\n",
       "      <td>-1.109104</td>\n",
       "      <td>-1.123769</td>\n",
       "      <td>-0.742310</td>\n",
       "      <td>0.036543</td>\n",
       "      <td>0.061779</td>\n",
       "      <td>-0.890730</td>\n",
       "      <td>1.421403</td>\n",
       "      <td>0.091122</td>\n",
       "      <td>-0.029984</td>\n",
       "      <td>-0.229745</td>\n",
       "      <td>-0.170111</td>\n",
       "      <td>0.720764</td>\n",
       "      <td>-1.813131</td>\n",
       "      <td>-3.422662</td>\n",
       "      <td>-0.483676</td>\n",
       "      <td>-0.439951</td>\n",
       "      <td>0.026448</td>\n",
       "      <td>0.336944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041457</td>\n",
       "      <td>0.041457</td>\n",
       "      <td>0.041457</td>\n",
       "      <td>-0.517916</td>\n",
       "      <td>0.269485</td>\n",
       "      <td>0.231060</td>\n",
       "      <td>0.445673</td>\n",
       "      <td>-1.084964</td>\n",
       "      <td>0.282963</td>\n",
       "      <td>0.596060</td>\n",
       "      <td>1.321173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041457</td>\n",
       "      <td>0.041457</td>\n",
       "      <td>0.041457</td>\n",
       "      <td>-2.049653</td>\n",
       "      <td>-2.002098</td>\n",
       "      <td>-0.505727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             roic_ttm        ...          sharpe_ratio_120d\n",
       "000503.XSHE -0.512500        ...                   0.499285\n",
       "000606.XSHE -0.055995        ...                  -0.054728\n",
       "000676.XSHE -1.274996        ...                  -0.564930\n",
       "000835.XSHE -0.055995        ...                  -0.054728\n",
       "002072.XSHE -0.991742        ...                  -0.505727\n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors['2009-12-31'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Adding Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "period='M'\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2018-02-01'\n",
    "industry_code = ['I64','I65']\n",
    "dateList=get_period_date(period,start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_data=pd.DataFrame()\n",
    "\n",
    "for date in dateList[:-2]:\n",
    "    \n",
    "    temp=factors[date]  \n",
    "    if factor_data.empty:\n",
    "        factor_data=temp\n",
    "    else:\n",
    "        factor_data=factor_data.append(temp)\n",
    "dic={}\n",
    "for column in list(factor_data.columns[factor_data.isnull().sum() > 0]):\n",
    "    mean_val = factor_data[column].mean()\n",
    "    dic[column]=mean_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "date_train, date_test=train_test_split(dateList,test_size=0.4,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train set +y\n",
    "\n",
    "train_data=pd.DataFrame()\n",
    "\n",
    "for date in date_train:\n",
    "    \n",
    "    traindf=factors[date]\n",
    "    stockList=list(traindf.index)\n",
    "    \n",
    "    #acquire return data\n",
    "    data_close=get_price(stockList,date,dateList[dateList.index(date)+1],'1d','close')['close']\n",
    "    traindf['pchg']=data_close.iloc[-1]/data_close.iloc[0]-1\n",
    "\n",
    "    #replaceNan\n",
    "    for column in list(factor_data.columns[factor_data.isnull().sum() > 0]):\n",
    "        traindf[column].fillna(dic[column],inplace=True)\n",
    "        \n",
    "    #select first 30% (label=1) and last 30% (label=-1),rule out noises in between\n",
    "    traindf=traindf.sort_values('pchg',ascending=False)\n",
    "    traindf=traindf.iloc[:len(traindf['pchg'])//10*3,:].append(traindf.iloc[len(traindf['pchg'])//10*7:,:])\n",
    "    traindf['label']=list(traindf['pchg'].apply(lambda x:1 if x>np.mean(list(traindf['pchg'])) else -1))  \n",
    "    #traindf['label']=list(traindf['pchg'].apply(lambda x:1 if x>average_annual_return else -1))\n",
    "    if train_data.empty:\n",
    "        train_data=traindf\n",
    "    else:\n",
    "        train_data=train_data.append(traindf)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"train_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data={}\n",
    "\n",
    "for date in date_test[:-2]:\n",
    "    \n",
    "    testdf=factors[date]\n",
    "    stockList=list(testdf.index)\n",
    "    \n",
    "    data_close=get_price(stockList,date,dateList[dateList.index(date)+1],'1d','close')['close']\n",
    "    testdf['pchg']=data_close.iloc[-1]/data_close.iloc[0]-1\n",
    "\n",
    "    #replaceNan\n",
    "    for column in list(factor_data.columns[factor_data.isnull().sum() > 0]):\n",
    "        testdf[column].fillna(dic[column],inplace=True)\n",
    "\n",
    "\n",
    "    testdf=testdf.sort_values('pchg',ascending=False)\n",
    "    testdf=testdf.iloc[:len(testdf['pchg'])//10*3,:].append(testdf.iloc[len(testdf['pchg'])//10*7:,:])\n",
    "    testdf['label']=list(testdf['pchg'].apply(lambda x:1 if x>np.mean(list(testdf['pchg'])) else -1)) \n",
    "    \n",
    "    #testdf['label']=list(testdf['pchg'].apply(lambda x:1 if x>average_annual_return else -1))\n",
    "    test_data[date]=testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1806172"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = pickle.dumps(test_data) \n",
    "write_file('test_set.pkl', content, append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "MarkDown菜单",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
